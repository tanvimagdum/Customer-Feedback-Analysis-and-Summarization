{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tanvimagdum/Customer-Feedback-Analysis-and-Summarization/blob/main/MiniProject_IDMP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.4-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (2.32.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Downloading kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Prsu_JEcSXjh",
    "outputId": "1d876990-7172-478b-d15f-3cd1b83c7b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/omennoob/.cache/kagglehub/datasets/cynthiarempel/amazon-us-customer-reviews-dataset/versions/9\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"cynthiarempel/amazon-us-customer-reviews-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gR7RH7P3Sv8O",
    "outputId": "5900ae14-c7f3-489d-b884-eb8a1b481da6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/23 23:32:07 WARN Utils: Your hostname, Rohits-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.24 instead (on interface en0)\n",
      "24/11/23 23:32:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/23 23:32:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/23 23:32:20 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 2:======================================================>(405 + 6) / 411]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: integer (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- star_rating: string (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Data Loading and Setup\n",
    "path = \"/Users/omennoob/.cache/kagglehub/datasets/cynthiarempel/amazon-us-customer-reviews-dataset/versions/9\"\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"AmazonReviewsAnalysis\").config(\"spark.driver.memory\", \"16g\").getOrCreate()\n",
    "df = spark.read.csv(path, sep=\"\\t\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cY1z8sk6dlRm",
    "outputId": "16e61a85-383e-4d53-9f84-718f8c798239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- marketplace: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- product_parent: integer (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- star_rating: string (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- vine: string (nullable = true)\n",
      " |-- verified_purchase: string (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yQgHWe4kTqo-"
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, length, length, trim, when, size\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "\n",
    "# Convert text to lowercase and remove punctuation\n",
    "df_cleaned = df.withColumn(\"review_body\", lower(col(\"review_body\")))\n",
    "df_cleaned = df_cleaned.withColumn(\"review_body\", regexp_replace(col(\"review_body\"), \"[^a-zA-Z0-9\\\\s]\", \"\"))\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"review_body\", outputCol=\"tokens\")\n",
    "df_tokenized = tokenizer.transform(df_cleaned)\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "df_filtered = remover.transform(df_tokenized)\n",
    "\n",
    "# Filter Reviews by Ratings\n",
    "df_positive = df_filtered.filter(col(\"star_rating\") >= 4)\n",
    "df_negative = df_filtered.filter(col(\"star_rating\") <= 2)\n",
    "\n",
    "# Filter out NULL and empty values in review_body\n",
    "df_filtered = df_filtered.filter(col(\"review_body\").isNotNull())\n",
    "df_filtered = df_filtered.filter(length(trim(col(\"review_body\"))) > 0)\n",
    "\n",
    "# Add Sentiment Column\n",
    "df_filtered = df_filtered.withColumn(\n",
    "    \"sentiment\",\n",
    "    when(col(\"star_rating\") >= 4, \"positive\")\n",
    "    .when(col(\"star_rating\") <= 2, \"negative\")\n",
    "    .otherwise(\"neutral\")\n",
    ")\n",
    "\n",
    "# Remove rows with empty filtered_tokens\n",
    "df_filtered = df_filtered.filter(size(col(\"filtered_tokens\")) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "n1ItysH5UEYr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import col, length, trim, when, size\n",
    "# from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
    "\n",
    "# # Step 1: Filter out NULL and empty values in review_body\n",
    "# df_filtered = df_filtered.filter(col(\"review_body\").isNotNull())\n",
    "# df_filtered = df_filtered.filter(length(trim(col(\"review_body\"))) > 0)\n",
    "\n",
    "# # Step 2: Add Sentiment Column\n",
    "# df_filtered = df_filtered.withColumn(\n",
    "#     \"sentiment\",\n",
    "#     when(col(\"star_rating\") >= 4, \"positive\")\n",
    "#     .when(col(\"star_rating\") <= 2, \"negative\")\n",
    "#     .otherwise(\"neutral\")\n",
    "# )\n",
    "\n",
    "# # Step 3: Tokenize and Remove Stop Words\n",
    "# tokenizer = Tokenizer(inputCol=\"review_body\", outputCol=\"tokens_new\")  # Changed output column name\n",
    "# df_tokenized = tokenizer.transform(df_filtered)\n",
    "\n",
    "# remover = StopWordsRemover(inputCol=\"tokens_new\", outputCol=\"filteredTokens\")\n",
    "# df_filtered = remover.transform(df_tokenized)\n",
    "\n",
    "# # Step 4: Remove rows with empty filtered_tokens\n",
    "# df_filtered = df_filtered.filter(size(col(\"filteredTokens\")) > 0)\n",
    "\n",
    "# # Step 5: Fit CountVectorizer\n",
    "# cv = CountVectorizer(inputCol=\"filteredTokens\", outputCol=\"key_phrases\", vocabSize=50)\n",
    "# model = cv.fit(df_filtered)\n",
    "# df_with_phrases = model.transform(df_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 00:51:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/11/24 00:51:22 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "[Stage 80:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+----------+\n",
      "|product_category      |sentiment|prediction|\n",
      "+----------------------+---------+----------+\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "|Digital_Music_Purchase|positive |1.0       |\n",
      "+----------------------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Model Accuracy: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace, when, size, concat_ws, round\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Data Loading (Assuming df_cleaned is already created as per the provided script)\n",
    "\n",
    "# Step 1: Split Dataset\n",
    "train_data, test_data = df_filtered.randomSplit([0.8, 0.2], seed=42)  # 80-20 split\n",
    "\n",
    "# Step 2: Fit CountVectorizer on Training Data\n",
    "cv = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"key_phrases\", vocabSize=50)\n",
    "cv_model = cv.fit(train_data)\n",
    "\n",
    "# Transform both training and testing data\n",
    "train_transformed = cv_model.transform(train_data)\n",
    "test_transformed = cv_model.transform(test_data)\n",
    "\n",
    "# Step 3: Train a Classifier\n",
    "# Add numeric labels for sentiment\n",
    "train_transformed = train_transformed.withColumn(\n",
    "    \"label\",\n",
    "    when(col(\"sentiment\") == \"positive\", 1.0)\n",
    "    .when(col(\"sentiment\") == \"negative\", 0.0)\n",
    "    .otherwise(2.0)  # Neutral\n",
    ")\n",
    "\n",
    "test_transformed = test_transformed.withColumn(\n",
    "    \"label\",\n",
    "    when(col(\"sentiment\") == \"positive\", 1.0)\n",
    "    .when(col(\"sentiment\") == \"negative\", 0.0)\n",
    "    .otherwise(2.0)  # Neutral\n",
    ")\n",
    "\n",
    "# Train a Logistic Regression Model\n",
    "lr = LogisticRegression(featuresCol=\"key_phrases\", labelCol=\"label\")\n",
    "lr_model = lr.fit(train_transformed)\n",
    "\n",
    "# Step 4: Make Predictions\n",
    "predictions = lr_model.transform(test_transformed)\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print Predictions and Accuracy\n",
    "predictions.select(\"product_category\", \"sentiment\", \"prediction\").show(10, truncate=False)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "8A9fcuAiUWJb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|summary                                                                                                                                                          |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|great  rendition great  song                                                                                                                                     |\n",
      "|good music listen                                                                                                                                                |\n",
      "|good original needed hear parts easily heard one                                                                                                                 |\n",
      "|time worship surrender song  wonderful lyrics makes feel like praying                                                                                            |\n",
      "|longerbut love song                                                                                                                                              |\n",
      "|clint brown awesome song writer singer  recommend work comes heart                                                                                               |\n",
      "|laverne butler one underrated jazz singers time34ill never free34 five stars like workjust wish played live us                                                   |\n",
      "|reason often catch lyrics however getting lyrics good finally asked friend explain sound expected kind music still enjoyed buy anything everything singer finding|\n",
      "|stones best                                                                                                                                                      |\n",
      "|simply best                                                                                                                                                      |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "|summary                                                                                      |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "|wanted completely musical version                                                            |\n",
      "|ok expecting                                                                                 |\n",
      "|didnt care music                                                                             |\n",
      "|played hp windows 7 laptoprefund  ha ha ha                                                   |\n",
      "|didnt care music                                                                             |\n",
      "|wish rate lower                                                                              |\n",
      "|song amazing love purchased idea worst way purchase song ill stick buying play storeapp store|\n",
      "|didnt care music                                                                             |\n",
      "|expected                                                                                     |\n",
      "|granddaughter particularly like version                                                      |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "# Combine tokens back to sentences\n",
    "df_filtered = df_filtered.withColumn(\"summary\", concat_ws(\" \", col(\"filtered_tokens\")))\n",
    "\n",
    "# Summaries for each sentiment\n",
    "df_positive_summary = df_filtered.filter(col(\"sentiment\") == \"positive\").select(\"summary\").show(10, truncate=False)\n",
    "df_negative_summary = df_filtered.filter(col(\"sentiment\") == \"negative\").select(\"summary\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "mKghVYxyUYht"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:=====================================================>(410 + 1) / 411]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|    product_category|sentiment|  count|\n",
      "+--------------------+---------+-------+\n",
      "|Digital_Music_Pur...| negative|  79434|\n",
      "|Digital_Music_Pur...|  neutral|  67580|\n",
      "|Digital_Music_Pur...| positive|1646047|\n",
      "|              Sports|  neutral| 380493|\n",
      "|              Sports| positive|3873876|\n",
      "|              Sports| negative| 592585|\n",
      "|             Watches| negative| 138412|\n",
      "|             Watches|  neutral|  79799|\n",
      "|             Watches| positive| 752009|\n",
      "|            Outdoors| positive|1852733|\n",
      "|            Outdoors| negative| 271118|\n",
      "|            Outdoors|  neutral| 179295|\n",
      "|          Automotive| negative| 447339|\n",
      "|          Automotive| positive|2821247|\n",
      "|          Automotive|  neutral| 239661|\n",
      "|             Grocery| positive|1953551|\n",
      "|             Grocery| negative| 285133|\n",
      "|             Grocery|  neutral| 161362|\n",
      "|     Office Products|  neutral| 193883|\n",
      "|     Office Products| positive|2001881|\n",
      "+--------------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "insights = df_filtered.groupBy(\"product_category\", \"sentiment\").count()\n",
    "insights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1mA0DfIhUcPf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:=====================================================>(410 + 1) / 411]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+-----------+----------+\n",
      "|    product_category|sentiment|  count|total_count|percentage|\n",
      "+--------------------+---------+-------+-----------+----------+\n",
      "|Digital_Music_Pur...| positive|1646047|    1793061|      91.8|\n",
      "|Digital_Music_Pur...|  neutral|  67580|    1793061|      3.77|\n",
      "|Digital_Music_Pur...| negative|  79434|    1793061|      4.43|\n",
      "|              Sports| negative| 592585|    4846954|     12.23|\n",
      "|              Sports| positive|3873876|    4846954|     79.92|\n",
      "|              Sports|  neutral| 380493|    4846954|      7.85|\n",
      "|             Watches| positive| 752009|     970220|     77.51|\n",
      "|             Watches|  neutral|  79799|     970220|      8.22|\n",
      "|             Watches| negative| 138412|     970220|     14.27|\n",
      "|            Outdoors|  neutral| 179295|    2303146|      7.78|\n",
      "|            Outdoors| negative| 271118|    2303146|     11.77|\n",
      "|            Outdoors| positive|1852733|    2303146|     80.44|\n",
      "|          Automotive|  neutral| 239661|    3508247|      6.83|\n",
      "|          Automotive| positive|2821247|    3508247|     80.42|\n",
      "|          Automotive| negative| 447339|    3508247|     12.75|\n",
      "|             Grocery|  neutral| 161362|    2400046|      6.72|\n",
      "|             Grocery| negative| 285133|    2400046|     11.88|\n",
      "|             Grocery| positive|1953551|    2400046|      81.4|\n",
      "|     Office Products| negative| 445963|    2641727|     16.88|\n",
      "|     Office Products| positive|2001881|    2641727|     75.78|\n",
      "+--------------------+---------+-------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "# Group by product_category and calculate total reviews\n",
    "total_reviews = df_filtered.groupBy(\"product_category\").count().withColumnRenamed(\"count\", \"total_count\")\n",
    "\n",
    "# Join insights with total_reviews on product_category\n",
    "insights_with_totals = insights.join(total_reviews, on=\"product_category\", how=\"inner\")\n",
    "\n",
    "# Add the percentage column\n",
    "sentiment_stats = insights_with_totals.withColumn(\n",
    "    \"percentage\",\n",
    "    round((col(\"count\") / col(\"total_count\")) * 100, 2)\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "sentiment_stats.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
